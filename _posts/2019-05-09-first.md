---
published: true
title: "A more detailed solution to GDMC 2017"
categories:
  - video games
  - behavioral data
  - machine learning
  
  
## Prediction engineering and other specific concepts that are not usually included and shown within a data science project


While data science has become essential to almost all industries,  in video games - reducing player churn is crucial to increase player engagement and game
monetization; besides, data science and predictive analytics show promises of transforming the video game industry as personalized user experience.
Game data sets are very had to find publicly available, especially coming from  massively multiplayer online role-playing game, not to mention any data science
solution related to a specific business problem. For this, the Game Data Mining Competition 2017 organized by NCSoft provided a large data set from Blade and Soul
game log data. It consisted of one training dataset and two test datasets, for which results should be evaluated without output information. Each of the datasets covered different periods of time and
had information about different users. The aim of this competition  was to predict churn and life expectancy during a certain prediction period.

![]

This article covers the concepts and full implementation as applied to predicting customer churn to the data set from GDMC 2017. 
The project Jupyter Notebooks and Python files (organized as for a data production pipeline) for this  project are all available on GitHub.

When working with real-world data on a machine learning task, we define the problem, which means we have to develop our own labels - historical 
examples of what we want to predict-to train a supervised model. The idea of making our own labels may initially seem foreign to data scientists (myself included) 
who got started on Kaggle competitions or textbook datasets where the answers are already included, and this is the case of GDMC 2017. 
The concept behind prediction engineering-making labels to train a supervised machine learning model-is not a standardized process  and is done by data scientists 
on an as-needed basis. 

The inputs to prediction engineering are the parameters which define the prediction problem for the business requirement , and the historical dataset for finding 
examples of what we want to predict.
The output of prediction engineering is a label times table: a set of labels with negative and positive examples made from past data along with an associated 
cutoff time indicating when we have to stop using data to make features for that label.The labels are not complete without the cutoff time which represents when we have 
to stop using data to make features for a label. All the features for each label must use data from before this time to prevent the problem of data leakage. Cutoff times 
are a crucial part of building successful solutions to time-series problems that many companies do not account for. I have seen research paper describing the winning 
solution for this competition, accounting for the time after cuttoff as censored time. To be mentioned that using invalid data to make features leads to models that do 
well in development but fail in deployment.

Dataset for Players Churn